{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Data\n",
    "In my initial search to find a dataset of interest I continuely ran into aggregated data.  So I changed my search criteria to 'ML datasets' and discovered several repositories of data suitable for this project.  The dataset I've chosen deals with adult Autistic Spectrum Disorder Screening.  There are 704 samples of adults aged 17-61.  The features include responses to AQ-10 test along with other family history and demographical information.  The data was already split into feature and target sets as seen in the code below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "autism_screening_adult = fetch_ucirepo(id=426) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = autism_screening_adult.data.features \n",
    "y = autism_screening_adult.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(autism_screening_adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(autism_screening_adult.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Data\n",
    "From the initial variables output I could see that there were missing values in the age, ethnicity and relation features.  To get a better idea of what the dataset looked like, I printed out the unique responses for each category as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in X.columns[:]:\n",
    "    print(c, X[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above:\n",
    "-AQ-10 responses: Binary, appear clean.\n",
    "-age: Integer, Obvious outlier/miskey (383) and NaN.\n",
    "-gender: Binary, M/F that can be changed to 1/0.  \n",
    "-ethnicity: Categorical, NaN, 2 different others responses that can be combined.\n",
    "-jaundice: Binary, Y/N that can be changed to 1/0.\n",
    "-family_pdd: Binary, Y/N that can be changed to 1/0.\n",
    "-country_of_res: Categorical, Appears clean.\n",
    "-used_app_before: Binary, Y/N that can be changed to 1/0. (Curious how this was considered predictor of Autism) \n",
    "-result: Integer, Appears clean.\n",
    "-age_desc: Only one response that encompasses all but one of the ages.\n",
    "-relation: NaN (Curious how this was considered predictor of Autism) \n",
    "\n",
    "To resolve the issues stated above, I ran the following the code.  A print out to see the changes is included.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.jaundice.replace(('yes', 'no'), (1, 0), inplace=True)\n",
    "X.family_pdd.replace(('yes', 'no'), (1, 0), inplace=True)\n",
    "X.gender.replace(('m', 'f'), (1,0), inplace=True)\n",
    "X.age.replace(383, 38, inplace=True)\n",
    "X.ethnicity.replace('others', 'Others', inplace=True)\n",
    "X['ethnicity'].fillna('Others', inplace=True)\n",
    "X.drop(['age_desc', 'relation', 'used_app_before'], axis=1, inplace=True)\n",
    "mean_value = int(X['age'].mean())\n",
    "X['age'].fillna(value=mean_value, inplace=True) \n",
    "for c in X.columns[:]:\n",
    "    print(c, X[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding Categorical Data\n",
    "Both ethnicity and country_of_res features are categorical data that will be encoded to be handled in models.\n",
    "ohe = OneHotEncoder()\n",
    "encoded_data = ohe.fit_transform(X[['ethnicity']])\n",
    "X_encoded = pd.DataFrame(encoded_data.toarray(), columns=ohe.get_feature_names_out(['ethnicity']))\n",
    "X = pd.concat([X.drop('ethnicity', axis=1), X_encoded], axis=1)\n",
    "encoded_data = ohe.fit_transform(X[['country_of_res']])\n",
    "X_encoded = pd.DataFrame(encoded_data.toarray(), columns=ohe.get_feature_names_out(['country_of_res']))\n",
    "X = pd.concat([X.drop('country_of_res', axis=1), X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Training and Testing Dataset\n",
    "The data provided was already split between features (X) and target (y) data.  I will split the next cell splits the data further into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a Model\n",
    "Because my features are mostly binary or categorical with only 2 continuous variables (age, result), I will look at models that handle these types of features the best:  Logistic Regression,Random Forest, and SVM.\n",
    "\n",
    "To have a baseline model, I will first create, train and evaluate a Random Forest model with 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train,y_train)\n",
    "yhat = rfc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
